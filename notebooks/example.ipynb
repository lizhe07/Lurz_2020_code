{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook on how to load the transfer core and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import neuralpredictors as neur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataloaders object is a dictionary of 3 dictionaries: train, validation and test. Each of them contains the respective data from all datasets combined that were specified in paths. Here we only provide one dataset. While the responses are normalized, we exclude the input images from normalization. The following config was used in the paper (all arguments not in the config have the default value of the function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lurz2020.datasets.mouse_loaders import static_loaders\n",
    "\n",
    "paths = ['data/Lurz2020/static20457-5-9-preproc0']\n",
    "\n",
    "dataset_config = {'paths': paths, \n",
    "                  'batch_size': 64, \n",
    "                  'seed': 1, \n",
    "                  'cuda': True,\n",
    "                  'normalize': True, \n",
    "                  'exclude': \"images\"}\n",
    "\n",
    "dataloaders = static_loaders(**dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier = 'train'\n",
    "dataset_name = '20457-5-9-0'\n",
    "\n",
    "images, responses = [], []\n",
    "for x, y in dataloaders[tier][dataset_name]:\n",
    "    images.append(x.squeeze().cpu().data.numpy())\n",
    "    responses.append(y.squeeze().cpu().data.numpy())\n",
    "    \n",
    "images = np.vstack(images)\n",
    "responses = np.vstack(responses)\n",
    "\n",
    "print('The \\\"{}\\\" set of dataset \\\"{}\\\" contains the responses of {} neurons to {} images'.format(tier, dataset_name, responses.shape[1], responses.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some example images and the neural responses\n",
    "n_images = 5\n",
    "max_response = responses[:n_images].max()\n",
    "\n",
    "for i in range(n_images):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15,4))\n",
    "    axs[0].imshow(images[i])\n",
    "    axs[1].plot(responses[i])\n",
    "    axs[1].set_xlabel('neurons')\n",
    "    axs[1].set_ylabel('responses')\n",
    "    axs[1].set_ylim([0, max_response])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load the transfer core later on, the arguments in the model config that concern the architecture of the model can not be changed. The following config was used in the paper (all arguments not in the config have the default value of the function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lurz2020.models.models import se2d_fullgaussian2d\n",
    "\n",
    "model_config = {'init_mu_range': 0.55,\n",
    "                'init_sigma': 0.4,\n",
    "                'input_kern': 15,\n",
    "                'hidden_kern': 13,\n",
    "                'gamma_input': 1.0,\n",
    "                'grid_mean_predictor': {'type': 'cortex',\n",
    "                                        'input_dimensions': 2,\n",
    "                                        'hidden_layers': 0,\n",
    "                                        'hidden_features': 0,\n",
    "                                        'final_tanh': False},\n",
    "                'gamma_readout': 2.439}\n",
    "\n",
    "model = se2d_fullgaussian2d(**model_config, dataloaders=dataloaders, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the weights of the transfer core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load the weights of the transfer core onto the model that you built above. The argument `strict=False` ensures that only matching keys are loaded. The readout keys are thus discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = torch.load('models/transfer_model.pth.tar') \n",
    "model.load_state_dict(transfer_model, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lurz2020.training.trainers import standard_trainer as trainer\n",
    "\n",
    "# If you want to allow fine tuning of the core, set detach_core to False\n",
    "detach_core=True\n",
    "if detach_core:\n",
    "    print('Core is fixed and will not be fine-tuned')\n",
    "else:\n",
    "    print('Core will be fine-tuned')\n",
    "\n",
    "trainer_config = {'track_training': True,\n",
    "                  'detach_core': detach_core}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, output, model_state = trainer(model=model, dataloaders=dataloaders, seed=1, **trainer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict neural responses to an image (here from the train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some example images and the neural responses\n",
    "n_images = 5\n",
    "max_response = responses[:n_images].max()\n",
    "\n",
    "for i in range(n_images):\n",
    "    input_image = images[i]\n",
    "    predicted_response = model(torch.from_numpy(input_image).view(1,1,36,64).cuda())\n",
    "    predicted_response = predicted_response.squeeze().cpu().data.numpy()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20,4))\n",
    "    axs[0].imshow(input_image)\n",
    "    axs[1].plot(responses[i])\n",
    "    axs[2].plot(predicted_response)\n",
    "    axs[1].set_xlabel('neurons')\n",
    "    axs[2].set_xlabel('neurons')\n",
    "    axs[1].set_ylabel('responses')\n",
    "    axs[2].set_ylabel('predicted responses')\n",
    "    axs[1].set_ylim([0, max_response])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the performance of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lurz2020.utility.measures import get_correlations, get_fraction_oracles\n",
    "\n",
    "train_correlation = get_correlations(model, dataloaders[\"train\"], device='cuda', as_dict=False, per_neuron=False)\n",
    "validation_correlation = get_correlations(model, dataloaders[\"validation\"], device='cuda', as_dict=False, per_neuron=False)\n",
    "test_correlation = get_correlations(model, dataloaders[\"test\"], device='cuda', as_dict=False, per_neuron=False)\n",
    "\n",
    "# Fraction Oracle can only be computed on the test set. It requires the dataloader to give out batches of repeats of images. \n",
    "# This is achieved by building a dataloader with the argument \"return_test_sampler=True\"\n",
    "oracle_dataloader = static_loaders(**dataset_config, return_test_sampler=True, tier='test')\n",
    "fraction_oracle = get_fraction_oracles(model=model, dataloaders=oracle_dataloader, device='cuda')[0]\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print('Correlation (train set):      {0:.3f}'.format(train_correlation))\n",
    "print('Correlation (validation set): {0:.3f}'.format(validation_correlation))\n",
    "print('Correlation (test set):       {0:.3f}'.format(test_correlation))\n",
    "print('-----------------------------------------')\n",
    "print('Fraction oracle (test set):   {0:.3f}'.format(fraction_oracle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
